{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Used In Order To Be Able To Import The Data from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://g.co/bard/share/ff1d6b646bb3;\n",
    "https://g.co/bard/share/2c5926525245;\n",
    "https://g.co/bard/share/fcb3f1361519;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/frankieinguanez/com.mcast.adad2023/main/football_striker_score.csv\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('football_striker_score.csv', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"File downloaded successfully\")\n",
    "else:\n",
    "    print(\"Error downloading file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get the path to the folder containing the CSV files\n",
    "folder_path = \"C:\\Users\\User\\OneDrive\\Advanced Data Analytics\\Home Assignment Research\\GitHub\\Advanced-Data-Analytics\\Football_Striker_Score.ipynb\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = os.listdir(folder_path)\n",
    "\n",
    "# Import each CSV file into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    if csv_file.endswith('football_striker_score.csv'):\n",
    "        df = pd.read_csv(os.path.join(folder_path, csv_file))\n",
    "\n",
    "        # Process the DataFrame\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/frankieinguanez/com.mcast.adad2023/main/football_striker_score.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('C:/Users/User/OneDrive/Advanced Data Analytics/Home Assignment Research/GitHub/Advanced-Data-Analytics/Football_Striker_Score.csv', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "        # Import the CSV file into a DataFrame\n",
    "        df = pd.read_csv('Football_Striker_Score.csv')\n",
    "\n",
    "        # Process the DataFrame\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"C:\\Users\\User\\OneDrive\\Advanced Data Analytics\\Home Assignment Research\\GitHub\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\football_striker_score.csv\"\n",
    "dataset = pd.read_csv(path)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "encoded_path = os.fsencode(path)\n",
    "decoded_path = encoded_path.decode(\"ISO-8859-1\")\n",
    "dataset = pd.read_csv(decoded_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the file path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the first 5 rows of the DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the file path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Print the first five rows of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying general information about the DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the file path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display the general information of the dataset\n",
    "print(dataset.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  In a code cell write code to display any issues with the data (presence of null values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### https://g.co/bard/share/18564be3ed5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Count the null values in each column\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "# Display the null values\n",
    "print(\"Number of null values in each column:\")\n",
    "print(null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Count the null values in each column\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "# Drop columns with null values\n",
    "filtered_data = dataset.dropna(axis=1)\n",
    "\n",
    "# Display information about the data frame\n",
    "dataset.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display null rows for each column\n",
    "for col in dataset.columns:\n",
    "    null_rows = dataset[dataset[col].isna()]\n",
    "(f\"Null rows for {col}:\")\n",
    "(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the null values in each column\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "# Drop columns with null values\n",
    "filtered_data = dataset.dropna(axis=1)\n",
    "\n",
    "# Display null rows for each column\n",
    "for col in dataset.columns:\n",
    "    null_rows = dataset[dataset[null_rows].isna()]\n",
    "(f\"Null rows for {null_rows}:\")\n",
    "(null_rows)\n",
    "\n",
    "# Display information about the data frame\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display rows that have null values\n",
    "null_rows = dataset[dataset.isnull().any(axis=1)]\n",
    "(\"Rows that have null values:\")\n",
    "(null_rows)\n",
    "\n",
    "# Remove rows with null values\n",
    "dataset.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Display information about the data frame\n",
    "(\"Data frame after removing rows with null values:\")\n",
    "(dataset.info(null_counts=True))\n",
    "(\"Data types per column name:\")\n",
    "(dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Geneal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and frequency counts for categorical columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            0 non-null      int64  \n",
      " 1   Age           0 non-null      float64\n",
      " 2   Acceleration  0 non-null      float64\n",
      " 3   Aggression    0 non-null      float64\n",
      " 4   Agility       0 non-null      float64\n",
      " 5   Balance       0 non-null      float64\n",
      " 6   BallControl   0 non-null      float64\n",
      " 7   Composure     0 non-null      float64\n",
      " 8   Crossing      0 non-null      float64\n",
      " 9   Dribbling     0 non-null      float64\n",
      " 10  Finishing     0 non-null      float64\n",
      " 11  Tackle        0 non-null      float64\n",
      " 12  Overall       0 non-null      float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 0.0 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display summary statistics for numerical columns\n",
    "numeric_columns = dataset.select_dtypes(include=[np.number])\n",
    "(\"Summary statistics for numerical columns:\")\n",
    "(numeric_columns.describe())\n",
    "\n",
    "# Display unique values and frequency counts for categorical columns\n",
    "categorical_columns = dataset.select_dtypes(include=[\"object\", \"category\"])\n",
    "print(\"Unique values and frequency counts for categorical columns:\")\n",
    "for col in categorical_columns.columns:\n",
    "    (f\"Unique values and frequency counts for {col}:\")\n",
    "    (dataset[col].value_counts())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualasation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  display histograms and scatter plots for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
