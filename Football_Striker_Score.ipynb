{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aquisition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Used In Order To Be Able To Import The Data from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://g.co/bard/share/ff1d6b646bb3;\n",
    "https://g.co/bard/share/2c5926525245;\n",
    "https://g.co/bard/share/fcb3f1361519;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/frankieinguanez/com.mcast.adad2023/main/football_striker_score.csv\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('football_striker_score.csv', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"File downloaded successfully\")\n",
    "else:\n",
    "    print(\"Error downloading file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/frankieinguanez/com.mcast.adad2023/main/football_striker_score.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open('C:/Users/User/OneDrive/Advanced Data Analytics/Home Assignment Research/GitHub/Advanced-Data-Analytics/Football_Striker_Score.csv', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "        # Import the CSV file into a DataFrame\n",
    "        df = pd.read_csv('Football_Striker_Score.csv')\n",
    "\n",
    "        # Process the DataFrame\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "encoded_path = os.fsencode(path)\n",
    "decoded_path = encoded_path.decode(\"ISO-8859-1\")\n",
    "dataset = pd.read_csv(decoded_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the file path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying the first 5 rows of the DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Aggression</th>\n",
       "      <th>Agility</th>\n",
       "      <th>Balance</th>\n",
       "      <th>BallControl</th>\n",
       "      <th>Composure</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Dribbling</th>\n",
       "      <th>Finishing</th>\n",
       "      <th>Tackle</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>28.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>28.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Age  Acceleration  Aggression  Agility  Balance  BallControl  \\\n",
       "0   0  32.0          89.0        63.0     89.0     63.0         93.0   \n",
       "1   3  30.0          88.0        78.0     86.0     60.0         91.0   \n",
       "2   5  28.0          79.0        80.0     78.0     80.0         89.0   \n",
       "3   9  29.0          78.0        50.0     75.0     69.0         85.0   \n",
       "4  13  28.0          88.0        80.0     90.0     87.0         87.0   \n",
       "\n",
       "   Composure  Crossing  Dribbling  Finishing  Tackle  Overall  \n",
       "0       95.0      85.0       91.0       94.0     NaN     94.0  \n",
       "1       83.0      77.0       86.0       94.0     NaN     92.0  \n",
       "2       87.0      62.0       85.0       91.0     NaN     91.0  \n",
       "3       86.0      68.0       84.0       91.0     NaN     90.0  \n",
       "4       86.0      80.0       90.0       85.0     NaN     89.0  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five rows of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying general information about the DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3100 entries, 0 to 3099\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            3100 non-null   int64  \n",
      " 1   Age           3097 non-null   float64\n",
      " 2   Acceleration  3097 non-null   float64\n",
      " 3   Aggression    3097 non-null   float64\n",
      " 4   Agility       3097 non-null   float64\n",
      " 5   Balance       3097 non-null   float64\n",
      " 6   BallControl   3097 non-null   float64\n",
      " 7   Composure     3097 non-null   float64\n",
      " 8   Crossing      3097 non-null   float64\n",
      " 9   Dribbling     3097 non-null   float64\n",
      " 10  Finishing     3097 non-null   float64\n",
      " 11  Tackle        0 non-null      float64\n",
      " 12  Overall       3097 non-null   float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 315.0 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the file path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display the general information of the dataset\n",
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  In a code cell write code to display any issues with the data (presence of null values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### https://g.co/bard/share/18564be3ed5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Count the null values in each column\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "# Display the null values\n",
    "print(\"Number of null values in each column:\")\n",
    "print(null_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Count the null values in each column\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "# Drop columns with null values\n",
    "filtered_data = dataset.dropna(axis=1)\n",
    "\n",
    "# Display information about the data frame\n",
    "dataset.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display null rows for each column\n",
    "for col in dataset.columns:\n",
    "    null_rows = dataset[dataset[col].isna()]\n",
    "(f\"Null rows for {col}:\")\n",
    "(null_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the null values in each column\n",
    "null_values = dataset.isna().sum()\n",
    "\n",
    "# Drop columns with null values\n",
    "filtered_data = dataset.dropna(axis=1)\n",
    "\n",
    "# Display null rows for each column\n",
    "for col in dataset.columns:\n",
    "    null_rows = dataset[dataset[null_rows].isna()]\n",
    "(f\"Null rows for {null_rows}:\")\n",
    "(null_rows)\n",
    "\n",
    "# Display information about the data frame\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display rows that have null values\n",
    "null_rows = dataset[dataset.isnull().any(axis=1)]\n",
    "(\"Rows that have null values:\")\n",
    "(null_rows)\n",
    "\n",
    "# Remove rows with null values\n",
    "dataset.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Display information about the data frame\n",
    "(\"Data frame after removing rows with null values:\")\n",
    "(dataset.info(null_counts=True))\n",
    "(\"Data types per column name:\")\n",
    "(dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Geneal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values and frequency counts for categorical columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            0 non-null      int64  \n",
      " 1   Age           0 non-null      float64\n",
      " 2   Acceleration  0 non-null      float64\n",
      " 3   Aggression    0 non-null      float64\n",
      " 4   Agility       0 non-null      float64\n",
      " 5   Balance       0 non-null      float64\n",
      " 6   BallControl   0 non-null      float64\n",
      " 7   Composure     0 non-null      float64\n",
      " 8   Crossing      0 non-null      float64\n",
      " 9   Dribbling     0 non-null      float64\n",
      " 10  Finishing     0 non-null      float64\n",
      " 11  Tackle        0 non-null      float64\n",
      " 12  Overall       0 non-null      float64\n",
      "dtypes: float64(12), int64(1)\n",
      "memory usage: 0.0 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "path = \"C:\\\\Users\\\\User\\\\OneDrive\\\\Advanced Data Analytics\\\\Home Assignment Research\\\\GitHub\\\\-com.mcast.adad2023.a02.Nwafor_Emmanuel\\\\football_striker_score.csv\"\n",
    "\n",
    "# Remove all Unicode escape sequences from the file path\n",
    "cleaned_path = re.sub(r\"\\\\U[0-9a-fA-F]{8}\", \"\", path)\n",
    "\n",
    "# Check if any Unicode escape sequences were removed\n",
    "if cleaned_path != path:\n",
    "    print(\"Removed Unicode escape sequences from the path:\", cleaned_path)\n",
    "\n",
    "# Read the CSV file using the cleaned path\n",
    "dataset = pd.read_csv(cleaned_path)\n",
    "\n",
    "# Display summary statistics for numerical columns\n",
    "numeric_columns = dataset.select_dtypes(include=[np.number])\n",
    "(\"Summary statistics for numerical columns:\")\n",
    "(numeric_columns.describe())\n",
    "\n",
    "# Display unique values and frequency counts for categorical columns\n",
    "categorical_columns = dataset.select_dtypes(include=[\"object\", \"category\"])\n",
    "print(\"Unique values and frequency counts for categorical columns:\")\n",
    "for col in categorical_columns.columns:\n",
    "    (f\"Unique values and frequency counts for {col}:\")\n",
    "    (dataset[col].value_counts())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualasation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  display histograms and scatter plots for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'overall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\adad\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\adad\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\adad\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'overall'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [225]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Check for missing values in the 'overall' column\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnew_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing values found in the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Replace missing values with the median of the 'overall' column\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\adad\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\adad\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'overall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Check if the 'overall' column exists in the DataFrame\n",
    "if \"overall\" in dataset.columns:\n",
    "    # Create a copy of the DataFrame\n",
    "    new_dataset = dataset.copy()\n",
    "\n",
    "    # Check for missing values in the 'overall' column\n",
    "    if new_dataset[\"overall\"].isna().values.any():\n",
    "        print(\"Missing values found in the 'overall' column.\")\n",
    "        # Replace missing values with the median of the 'overall' column\n",
    "        new_dataset[\"overall\"].fillna(new_dataset[\"overall\"].median(), inplace=True)\n",
    "\n",
    "        # Convert the 'overall' column to a numeric type\n",
    "        new_dataset[\"overall\"] = pd.to_numeric(new_dataset[\"overall\"], errors=\"coerce\")\n",
    "\n",
    "        # Extract the 'overall' column as a Series\n",
    "        overall_ranking_series = new_dataset[\"overall\"]\n",
    "\n",
    "        # Sort the 'overall' Series\n",
    "        sorted_overall_ranking_series = overall_ranking_series.sort_values(ascending=False)\n",
    "\n",
    "        # Select the top 10 players\n",
    "        top_10_players = sorted_overall_ranking_series.head(10)\n",
    "\n",
    "        # Display statistics of the top 10 overall ranking players\n",
    "        print(\"Statistics of the top 10 overall ranking players:\")\n",
    "        print(top_10_players.describe())\n",
    "else:\n",
    "    print(\"The 'overall' column does not exist in the DataFrame.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
